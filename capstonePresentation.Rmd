---
title: "JHU Coursera Capstone Presentation"
author: "bluebonobo"
date: "`r Sys.Date()`"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## The Application
The Shiny application developed for the Capstone assignment predicts the next word in a sentence. The user enters a series of word and the model predicts the next word using a Natural Language Statistical Model. The user interface is shown below. A documentation tab presents the content also available in this presentation

*For first lookup, expect slow response time to allow on time load of ngrams files*

![](https://raw.githubusercontent.com/bluebonobo/coursera_hopkins_capstoneproject/main/shinyapp/CapstoneShinyApp/WWW/Asset%201.png)


## The Model
To build the model, we use a corpus of blogs, news and twitter entires provided as part of the assignment.

- We have cleaned up the blogs, news and twitter entries to remove stop words, profanity
- The text resources are loaded in a VCorpus object which is then tokenized. We tokenize the corpus in bigrams, trigrams and 4grams
- We then build a DocumentTerm Matrix and calculate frequencies of each gram
- The model will be statistical based on a n-grams approach [see this article](https://towardsai.net/p/nlp/how-do-language-models-predict-the-next-word) or [this article](https://towardsdatascience.com/sentence-generation-with-n-gram-21a5eef36a1b)


## The Algorithm

- Given the number of words in the input text, we look up the most frequent bigram, trigram or 4gram
- If the ngram lookup does not return a match, we call the (n-1)gram lookup. This strategy is refered to as **backoff**. Meaning the highest order ngram lookup is called and if no match is identified, the algorithm backs off to the next lower order ngram and so on.

## Resources and Considerations
- The Shiny application can be found [here](https://bluebonobo.shinyapps.io/CapstoneProjectShinyApp/)
- The Source code repository can be found [here](https://github.com/bluebonobo/coursera_hopkins_capstoneproject)
- This presentation can be found [here](https://rpubs.com/bluebonobo/capstoneproject)

Note that in order to deploy the application on ShinyApps.io, I had to use the ngrams files built on a sample corpus as the full ngrams files would create a out of memory error in ShinyApps.io. This error is widely reported in the forums and most students worked around this by using sample corpus. The complete .rds ngrams files can be found in my github repository





Thank you - Bluebonobo





